{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Downloading data from XNAT\n",
    "Niall Bourke (n.bourke@imperial.ac.uk)\n",
    "  \n",
    "#### Version 3.0 \n",
    "\n",
    "Updates:   \n",
    "~ 2018 Maria Yanez-Lopez  \n",
    "~ 24/09/2019: Checks for data that is already pulled from xnat to allow rolling updating of data on the HPC  \n",
    "~ 12/10/2021: Adapting for new broken XNAT. **Requires project access**  \n",
    "~ Nov 2021: incorporation of BIDS converter scripts \n",
    "~ May 2022: Documentation & containerisation \n",
    " \n",
    "  \n",
    "### Documentation: \n",
    "\n",
    "This scripts downloads DICOM data from XNAT according to users specifications.\n",
    "\n",
    "Updated envionment libraries for py3\n",
    "\n",
    "https://github.com/pyxnat/pyxnat/blob/master/pyxnat/core/downloadutils.py\n",
    "\n",
    "https://groups.google.com/forum/#!topic/xnat_discussion/K8h4VP4CBMg\n",
    "\n",
    "https://gist.github.com/mattsouth/db8f2d09acf3c57ba605fa93c4e8d03e\n",
    "\n",
    "https://ubuntuforums.org/showthread.php?t=786879\n",
    "\n",
    "https://wiki.imperial.ac.uk/pages/viewpage.action?spaceKey=HPC&title=Jupyter\n",
    "\n",
    "## Dependencies\n",
    "Some requirements need to be in place. This should be setup from home dir in terminal. Setup py3.5 env (with jupyter kernal = ipykernel)  \n",
    "\n",
    "\n",
    ">module load anaconda3/personal anaconda â€“setup  \n",
    ">conda create -n py35 python=3.5 ipykernel  \n",
    ">source activate py35  \n",
    ">pip install pyxnat  \n",
    ">conda install jq  #pip install jq  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, getpass                           \n",
    "from pyxnat import Interface\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce your XNAT login details (same as college credentials) and project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userName = input('Type XNAT User Name: ')\n",
    "passWord = getpass.getpass('Type XNAT Password: ')\n",
    "projectID = input('Type XNAT Project ID: ')\n",
    "server = 'http://cif-xnat.hh.med.ic.ac.uk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('INPUT')\n",
    "print ('Server: ', server)\n",
    "print ('Username: ', userName)\n",
    "print ('Password: ', ''.join(['*']*len(passWord)))\n",
    "print ('ProjectID: ', projectID )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PYXNAT interface\n",
    "*If no files are detected check password and access to xnat project*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central = Interface(server=server, user=userName, password=passWord)\n",
    "\n",
    "# Full project download:\n",
    "subjects = central.select.project(projectID).subjects().get()\n",
    "\n",
    "# individual subject:\n",
    "#subID= \"CIF3_S04363\" \n",
    "#subjects = central.select.project(projectID).subjects(subID).get()\n",
    "\n",
    "print(subjects)\n",
    "#head(subjects)\n",
    "allSessions = []\n",
    "number_subjects = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Browse through project, collect subjects/sessions/scans and print subject labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, subject in enumerate(subjects):\n",
    "    label = central.select.project(projectID).subject(subject).label()\n",
    "    print (label, ('%i/%i' % (i+1, len(subjects))))\n",
    "    sessions = central.select.project(projectID).subjects(subject).experiments().get()\n",
    "    allSessions.append(sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the output directory, where the datasets will be saved from XNAT\n",
    "\n",
    "* The path is currently set to c3nl_djs_working_dir/ephemeral directory and will download to a folder with the name of project being downloaded\n",
    "* For curation purposes a defined location should be set to host the raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirName = os.path.join('/rds/general/project/c3nl_djs_imaging_data/live/data/raw/', projectID)\n",
    "\n",
    "# Create target Directory if don't exist\n",
    "if not os.path.exists(dirName):\n",
    "    os.mkdir(dirName)\n",
    "    print(\"Directory \" , dirName ,  \" Created \")\n",
    "else:    \n",
    "    print(\"Directory \" , dirName ,  \" already exists\")\n",
    "        \n",
    "Results_Dir = dirName # needs to exist or next cell will throw error\n",
    "idx_dir = ('/rds/general/project/c3nl_djs_imaging_data/live/data/indexFiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download datasets\n",
    "This script will look into the predefined project. Check the printed output to look for duplicates and incomplete datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "\n",
    "subjectCounter = 0\n",
    "for s, subjectID in enumerate(subjects):\n",
    "    subjectLabel = central.select.project(projectID).subject(subjectID).label()\n",
    "    \n",
    "    for experimentID in allSessions[s]:\n",
    "            scans = central.select.project(projectID).subject(subjectID).experiments(experimentID).scans()\n",
    "            scanIDs = scans.get()\n",
    "            \n",
    "            coll = central.select.project(projectID).subject(subjectID).experiments(experimentID)\n",
    "            for ese in coll:\n",
    "                explab = ese.attrs.get('label')\n",
    "            \n",
    "            # Check if data has already been pulled\n",
    "            dataCheck = glob.glob(Results_Dir + \"/\" + subjectLabel + \"/*\" + explab )\n",
    "            #print(\"sub label is: \" + subjectLabel)\n",
    "            #print(\"exp label is: \" + explab)\n",
    "            dataCheck = ''.join(dataCheck) # covert list to string\n",
    "            #print(\"data path is: \" + dataCheck)\n",
    "            if not os.path.exists(dataCheck):\n",
    "                print(\"Downloading:\", explab)        \n",
    "                number_subjects+=1\n",
    "            \n",
    "                if len(scanIDs) == 0:\n",
    "                    print(\"There are no scans to download for\", explab)\n",
    "                else:\n",
    "                    filenames = central.select.project(projectID).subject(subjectID).experiment(experimentID).scans()\n",
    "                    filenames.download(Results_Dir, type='ALL', extract=False) #removeZip=True   \n",
    "            else:\n",
    "                print(explab + \" already pulled\")\n",
    "print (\"The total number of scanning sessions downloaded is = \" + str(number_subjects))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweet now we're rolling! \n",
    "To make life easy all our labs notebooks are going assume a BIDS format.\n",
    "The following curates data in a standardised format, which will be the starting point of analysis pipelines\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "#### A CIF_config.json has been created to match MRI acquisitions and label them in the correct format. \n",
    "This may need to be updated if new seqences are being collected. \n",
    "Requires the labels from the scan card for each acquisition being formated (NOTE: How these are displayed on the XNAT website unhelpfuly does not necessarily match with the actual data labels!)  \n",
    "**The following bids scrips are currently hardcoded to use the config file located in the shared dependencies folder**\n",
    "\n",
    "#### Index files\n",
    "* I have used XDC (xnat data cliant) to pull metaData about scan labels from xnat.\n",
    "\n",
    "* The bids scripts are hardcoded to look for this metaData in a indexFiles directory within the working dir. This should contain two files for the project PROJECT_experiments.csv and PROJECT_subject.csv\n",
    "\n",
    "* The following XDC function can be used to pull project and subject information from xnat\n",
    "\n",
    "\n",
    "### XDC setup\n",
    "**This folder has been saved in the dependencies folder on the cluster (17/11/2021)** \n",
    "Installed via the following instructions:\n",
    "https://wiki.xnat.org/xnat-tools/xnatdataclient\n",
    "\n",
    "### jq setup\n",
    "\n",
    "**UPDATE**\n",
    "- Pass python variables and save output to working directory\n",
    "- Check paths in bash scripts called (CIF_unzip & bids_beta)\n",
    "- For BIDS need to make sure jq is installed in the envs that is run (i.e. make sure to load py35 in terminal and jq is installed in that env)\n",
    ">brew install jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BIDS curation \n",
    "- Pulls metadata from xnat and stores in csv\n",
    "- Runs wrapper for dcm2niix (CIF_unzip)\n",
    "- Runs Curation script (bids_proc). \n",
    "\n",
    "* Some project on xnat are prefixed 'Study__' this has caused problems and seperate scripts have been included to handle this (CIF_unzip_Study__ bids_proc_Study__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$userName\" \"$passWord\" \"$projectID\" \n",
    "\n",
    "# Set variables\n",
    "username=${1} \n",
    "password=${2}\n",
    "ID=${3}\n",
    "path=/rds/general/project/c3nl_djs_imaging_data/live/data/indexFiles\n",
    "dep=/rds/general/project/c3nl_shared/live/dependencies\n",
    "cwd=$(pwd)\n",
    "job=${cwd}/bidJob.txt\n",
    "\n",
    "# Find index from xnat\n",
    "input1=\"http://wmec-transtec1.hh.med.ic.ac.uk:/data/archive/projects/\"${ID}\"/experiments?format=csv\"\n",
    "input2=\"http://wmec-transtec1.hh.med.ic.ac.uk:/data/archive/projects/\"${ID}\"/subjects?format=csv\"\n",
    "\n",
    "# Run xnat data client\n",
    "## This updates the indexing information from xnat which the bids script relies on\n",
    "java -jar /rds/general/project/c3nl_shared/live/dependencies/data-client-shadow-1.7.6/lib/XnatDataClient-1.7.6-all.jar -u ${username} -p ${password} -r ${input1} -o ${path}/${ID}_experiments  \n",
    "java -jar /rds/general/project/c3nl_shared/live/dependencies/data-client-shadow-1.7.6/lib/XnatDataClient-1.7.6-all.jar -u ${username} -p ${password} -r ${input2} -o ${path}/${ID}_subject\n",
    "\n",
    "# CIF_unzip\n",
    "# bids_proc \n",
    "\n",
    "# Set job script\n",
    "echo \"source activate py35; ${cwd}/lib/CIF_unzip_Study__ -i ${ID}; ${cwd}/lib/bids_proc_Study__ -i ${ID} -c CIF_config.json\" > ${job}\n",
    "\n",
    "# Run job\n",
    "${dep}/hpcSubmit ${job} 12:00:00 3 6Gb\n",
    "echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "head ${job}\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and indexing data from xnat\n",
    "\n",
    "The following functions are in the dependencies folder on the Imperial HPC along with the CIF_config.json file\n",
    "* New aquisitions need to be added to the CIF_config.json (this is a sort of dictionary for standardised naming)\n",
    "\n",
    "#### 1: CIF_unzip -i project\n",
    "    Unzips & indexes files downloaded from XNAT with more meaningfull labels such as participant ID and scan session.  \n",
    "    This sets up the initial file structure to run the conversion to BIDS.\n",
    "    \n",
    "#### 2: bids_proc -i project -c config.json\n",
    "    Loops over all subjects->sessions->modalities->scans and converts DICOMS to NIFTI.   \n",
    "    The labels for each of the scans on the scan card are then converted to match the BIDS format and file structure  \n",
    "    \n",
    "#### Sources of error\n",
    "* Conversion to nii at this point should be robust and all data will be in raw under the project name\n",
    "* Missing data in source directory is likely due to a **new exception** in how something was named on the scanner - this should be added to the config.json file. Be careful not to clash with similar names. \n",
    "* This works well for data comming off the CIF scanner (Imperial). Data from new sites have to be checked/validated as something in the structure may cause unexpected outcomes. \n",
    "\n",
    "\n",
    "##### Known bugs\n",
    "XDC as an alias set in .bash_profile wont be sourced in Jupyter, not sure why. \n",
    "\n",
    "Point to it by adding the following lines to your .bash_profile\n",
    "#XDC\n",
    "alias XDC='java -jar /rds/general/user/**nbourke**/home/data-client-shadow-1.7.6/lib/XnatDataClient-1.7.6-all.jar'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
